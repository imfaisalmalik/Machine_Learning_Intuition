{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Variable Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Vectorization\n",
    "- To implement Multi Linear Regression, we use vectorization technique which makes the code shorter and faster.\n",
    "- In vectorization technique, we can represent all features with a single vector quantity instead of denoting each feature with a single variable.\n",
    "- Thus, appearently,  it looks like a single variable function but under the hood, all features are processed easily with fast and shorter code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In pyhton, we use Numpy Library to create vectors and performing different Vectors' operations.\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) Numpy Vector Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [0. 0. 0. 0.]; \n",
      "shape: (4,), dtype: float64; dimension: 1\n",
      "a: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]; \n",
      "shape: (4, 5), dtype: int64; dimension: 2\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((4,))\n",
    "print(f\"a: {a}; \\nshape: {a.shape}, dtype: {a.dtype}; dimension: {a.ndim}\")\n",
    "\n",
    "a = np.zeros((4,5), dtype=int)\n",
    "a = np.zeros((4,5), dtype='int64')\n",
    "print(f\"a: {a}; \\nshape: {a.shape}, dtype: {a.dtype}; dimension: {a.ndim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [[0 1]\n",
      " [2 3]]; \n",
      "shape: (2, 2), dtype: int32; dimension: 2\n",
      "b: [[1. 1.]\n",
      " [1. 1.]]; \n",
      "shape: (2, 2), dtype: float64; dimension: 2\n",
      "\n",
      "***** Element-wise Operations *****\n",
      "Addition a+b: [[1. 2.]\n",
      " [3. 4.]]\n",
      "\n",
      "Scalar Multiplication b*2: [[2. 2.]\n",
      " [2. 2.]]; \n",
      "shape: (2, 2), dtype: float64; dimension: 2\n",
      "new_b: [[3. 2.]\n",
      " [4. 2.]]\n",
      "Multiplication c = a*b: [[0. 2.]\n",
      " [8. 6.]]\n",
      "\n",
      "Slicing c[:,0]: [0. 8.]\n"
     ]
    }
   ],
   "source": [
    "# Numpy Operations\n",
    "# create 2 vectors\n",
    "\n",
    "a = np.arange(4)\n",
    "a = a.reshape((2,-1)) # -1 means set the shape of 2nd dmesntion as per feasibilty.\n",
    "print(f\"a: {a}; \\nshape: {a.shape}, dtype: {a.dtype}; dimension: {a.ndim}\")\n",
    "\n",
    "b = np.ones((2,2))\n",
    "print(f\"b: {b}; \\nshape: {b.shape}, dtype: {b.dtype}; dimension: {b.ndim}\")\n",
    "\n",
    "print(\"\\n***** Element-wise Operations *****\")\n",
    "\n",
    "print(f\"Addition a+b: {a+b}\")\n",
    "b = b*2  # Multiplied vector b with sacalar (2)\n",
    "print(f\"\\nScalar Multiplication b*2: {b}; \\nshape: {b.shape}, dtype: {b.dtype}; dimension: {b.ndim}\")\n",
    "\n",
    "b[0][0] = 3; b[1][0] = 4\n",
    "print(f\"new_b: {b}\")\n",
    "c = a*b\n",
    "print(f\"Multiplication c = a*b: {c}\")\n",
    "\n",
    "print(f\"\\nSlicing c[:,0]: {c[:,0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot Product c = a.b: [[ 4.  2.]\n",
      " [18. 10.]]; \n",
      "shape: (2, 2), dtype: float64; dimension: 2\n"
     ]
    }
   ],
   "source": [
    "# Dot Product (2D)\n",
    "c = np.dot(a,b)\n",
    "print(f\"Dot Product c = a.b: {c}; \\nshape: {c.shape}, dtype: {c.dtype}; dimension: {c.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii) Dot Product using Custom Function\n",
    "\n",
    "Let's implement our own version of the dot product:\n",
    "\n",
    "**Using a for loop**, implement a function which returns the dot product of two vectors. The function to return given inputs $a$ and $b$:\n",
    "$$ x = \\sum_{i=0}^{n-1} a_i b_i $$\n",
    "Assume both `a` and `b` are the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_dot_product(a,b):\n",
    "    dot_procut = np.array(0)\n",
    "    for i in range(len(a)):\n",
    "        dot_procut += a[i]*b[i]\n",
    "    return dot_procut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:[1 2 3 4] \n",
      "b:[-1  4  3  2]\n",
      "NumPy 1-D c = a.b = 24, c.shape = () \n"
     ]
    }
   ],
   "source": [
    "# test 1-D\n",
    "a2 = np.array([1, 2, 3, 4])\n",
    "b2 = np.array([-1, 4, 3, 2])\n",
    "print(f\"a:{a2} \\nb:{b2}\")\n",
    "c = my_dot_product(a2, b2)\n",
    "print(f\"NumPy 1-D c = a.b = {c}, c.shape = {c.shape} \") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii) Dot Product using Numpy np.dot() Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:[1 2 3 4] \n",
      "b:[-1  4  3  2]\n",
      "NumPy 1-D np.dot(a, b) = 24, np.dot(a, b).shape = () \n",
      "NumPy 1-D np.dot(b, a) = 24, np.dot(a, b).shape = (), dtype: int32; dimension: 0\n"
     ]
    }
   ],
   "source": [
    "a2 = np.array([1, 2, 3, 4])\n",
    "b2 = np.array([-1, 4, 3, 2])\n",
    "print(f\"a:{a2} \\nb:{b2}\")\n",
    "c = np.dot(a2, b2)\n",
    "print(f\"NumPy 1-D np.dot(a, b) = {c}, np.dot(a, b).shape = {c.shape} \") \n",
    "c = np.dot(b2, a2)\n",
    "print(f\"NumPy 1-D np.dot(b, a) = {c}, np.dot(a, b).shape = {c.shape}, dtype: {c.dtype}; dimension: {c.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Multiple Variable Linear Regression\n",
    "\n",
    "<a name=\"toc_15456_1.1\"></a>\n",
    "#### i) Goals\n",
    "\n",
    "- Extend our regression model  routines to support multiple features\n",
    "    - Extend data structures to support multiple features\n",
    "    - Rewrite prediction, cost and gradient routines to support multiple features\n",
    "    - Utilize NumPy `np.dot` to vectorize their implementations for speed and simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii) Notations\n",
    "Here is a summary of some of the notations you will encounter, updated for multiple features.  \n",
    "\n",
    "|General <img width=70/> <br />  Notation  <img width=60/> | Description<img width=200/>| Python (if applicable) |\n",
    "|: ------------|: ------------------------------------------------------------||\n",
    "| $a$ | scalar, non bold                                                      ||\n",
    "| $\\mathbf{a}$ | vector, bold                                                 ||\n",
    "| $\\mathbf{A}$ | matrix, bold capital                                         ||\n",
    "| **Regression** |         |    |     |\n",
    "|  $\\mathbf{X}$ | training example matrix                  | `X_train` |   \n",
    "|  $\\mathbf{y}$  | training example  targets                | `y_train` \n",
    "|  $\\mathbf{x}^{(i)}$, $y^{(i)}$ | $i_{th}$Training Example | `X[i]`, `y[i]`|\n",
    "| m | number of training examples | `m`|\n",
    "| n | number of features in each example | `n`|\n",
    "|  $\\mathbf{w}$  |  parameter: weight,                       | `w`    |\n",
    "|  $b$           |  parameter: bias                                           | `b`    |     \n",
    "| $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ | The result of the model evaluation at $\\mathbf{x^{(i)}}$ parameterized by $\\mathbf{w},b$: $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)}+b$  | `f_wb` | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_2\"></a>\n",
    "#### iii) Problem Statement\n",
    "\n",
    "You will use the motivating example of housing price prediction. The training dataset contains three examples with four features (size, bedrooms, floors and, age) shown in the table below.  Note that, unlike the earlier labs, size is in sqft rather than 1000 sqft. This causes an issue, which you will solve in the next lab!\n",
    "\n",
    "| Size (sqft) | Number of Bedrooms  | Number of floors | Age of  Home | Price (1000s dollars)  |   \n",
    "| ----------------| ------------------- |----------------- |--------------|-------------- |  \n",
    "| 2104            | 5                   | 1                | 45           | 460           |  \n",
    "| 1416            | 3                   | 2                | 40           | 232           |  \n",
    "| 852             | 2                   | 1                | 35           | 178           |  \n",
    "\n",
    "You will build a linear regression model using these values so you can then predict the price for other houses. For example, a house with 1200 sqft, 3 bedrooms, 1 floor, 40 years old.  \n",
    "\n",
    "Please run the following code cell to create your `X_train` and `y_train` variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: [[2104    5    1   45]\n",
      " [1416    3    2   40]\n",
      " [ 852    2    1   35]]; \n",
      "shape: (3, 4), dtype: int32; dimension: 2\n",
      "y_train: [460 232 178]; \n",
      "shape: (3,), dtype: int32; dimension: 1\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([\n",
    "    [2104, 5, 1, 45],\n",
    "    [1416, 3, 2, 40],\n",
    "    [852, 2, 1, 35]\n",
    "])\n",
    "\n",
    "# OR Declare x_train as:\n",
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])\n",
    "\n",
    "print(f\"x_train: {x_train}; \\nshape: {x_train.shape}, dtype: {x_train.dtype}; dimension: {x_train.ndim}\")\n",
    "print(f\"y_train: {y_train}; \\nshape: {y_train.shape}, dtype: {y_train.dtype}; dimension: {y_train.ndim}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_2.2\"></a>\n",
    "#### iv) Parameter vector w, b\n",
    "\n",
    "* $\\mathbf{w}$ is a vector with $n$ elements.\n",
    "  - Each element contains the parameter associated with one feature.\n",
    "  - in our dataset, n is 4.\n",
    "  - notionally, we draw this as a column vector\n",
    "\n",
    "$$\\mathbf{w} = \\begin{pmatrix}\n",
    "w_0 \\\\ \n",
    "w_1 \\\\\n",
    "\\cdots\\\\\n",
    "w_{n-1}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "* $b$ is a scalar parameter.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For demonstration, $\\mathbf{w}$ and $b$ will be loaded with some initial selected values that are near the optimal. $\\mathbf{w}$ is a 1-D NumPy vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_init shape: (4,), b_init type: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "b_init = 785.1811367994083\n",
    "w_init = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "print(f\"w_init shape: {w_init.shape}, b_init type: {type(b_init)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v) Non-Vectorized Implementation of f(x) having Multiple Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Element by Element\n",
    "def predict_elem_by_elem(w, x, b):\n",
    "    \"\"\"\n",
    "    single predict using linear regression\n",
    "    \n",
    "    Args:\n",
    "      x (ndarray): Shape (n,) example with multiple features\n",
    "      w (ndarray): Shape (n,) model parameters    \n",
    "      b (scalar):  model parameter     \n",
    "      \n",
    "    Returns:\n",
    "      f_wb (scalar):  Model prediction\n",
    "    \"\"\"\n",
    "    f_wb = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        f_wb += w[i] * x[i] # Weighted Sum >> w1*x1 + w2*x2 + ...\n",
    "    f_wb = f_wb + b\n",
    "    return f_wb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vec: [2104    5    1   45], shape: (4,), type: <class 'numpy.ndarray'>\n",
      "w_init: [  0.39133535  18.75376741 -53.36032453 -26.42131618], shape: (4,), type: <class 'numpy.ndarray'>\n",
      "b_init: 785.1811367994083, type: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "x_vec = x_train[0,:]\n",
    "print(f\"x_vec: {x_vec}, shape: {x_vec.shape}, type: {type(x_vec)}\")\n",
    "print(f\"w_init: {w_init}, shape: {w_init.shape}, type: {type(w_init)}\")\n",
    "print(f\"b_init: {b_init}, type: {type(b_init)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_init:[  0.39133535  18.75376741 -53.36032453 -26.42131618], \n",
      "x_vec:[2104    5    1   45], \n",
      "b_init:785.1811367994083 >> f_wb:459.9999976194083\n"
     ]
    }
   ],
   "source": [
    "f_wb = predict_elem_by_elem(w_init, x_vec, b_init)\n",
    "print(\"w_init:{}, \\nx_vec:{}, \\nb_init:{} >> f_wb:{}\".format(w_init, x_vec, b_init, f_wb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vi) Vectorized Implementation of f(x) having Multiple Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, x, b):\n",
    "    f_wb = np.dot(w,x) + b\n",
    "    return f_wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_init:[  0.39133535  18.75376741 -53.36032453 -26.42131618], \n",
      "x_vec:[2104    5    1   45], \n",
      "b_init:785.1811367994083 >> f_wb:459.9999976194083\n"
     ]
    }
   ],
   "source": [
    "f_wb = predict(w_init, x_vec, b_init)\n",
    "print(\"w_init:{}, \\nx_vec:{}, \\nb_init:{} >> f_wb:{}\".format(w_init, x_vec, b_init, f_wb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_4\"></a>\n",
    "#### vii) Compute Cost With Multiple Variables\n",
    "The equation for the cost function with multiple variables $J(\\mathbf{w},b)$ is:\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 \\tag{3}$$ \n",
    "where:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b  \\tag{4} $$ \n",
    "\n",
    "\n",
    "In contrast to previous labs, $\\mathbf{w}$ and $\\mathbf{x}^{(i)}$ are vectors rather than scalars supporting multiple features.\n",
    "\n",
    "Below is an implementation of equations (3) and (4). Note that this uses a *standard pattern for this course* where a for loop over all `m` examples is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(x, y, w, b):\n",
    "    m = x.shape[0]\n",
    "    cost = 0\n",
    "    for i in range(m):\n",
    "        # f_wb = predict(w,x[i],b)\n",
    "        f_wb = np.dot(w,x[i]) + b\n",
    "        cost += (f_wb - y[i])**2\n",
    "    mse = cost/(2*m)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5578904428966628e-12\n"
     ]
    }
   ],
   "source": [
    "cost = compute_cost(x_train, y_train, w_init, b_init)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_5\"></a>\n",
    "# 3 Gradient Descent With Multiple Variables\n",
    "Gradient descent for multiple variables:\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\\;\n",
    "& w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{5}  \\; & \\text{for j = 0..n-1}\\newline\n",
    "&b\\ \\ = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "where, n is the number of features, parameters $w_j$,  $b$, are updated simultaneously and where  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{6}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{7}\n",
    "\\end{align}\n",
    "$$\n",
    "* m is the number of training examples in the data set\n",
    "\n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ is the model's prediction, while $y^{(i)}$ is the target value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) Compute Gradient with Multiple Variables (Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_gradient for multiple variables/features/predictors\n",
    "def compute_gradient(x, y, w, b):\n",
    "\n",
    "    m, n = x.shape           #(number of examples, number of features)\n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0\n",
    "\n",
    "    for i in range(m):\n",
    "        f_wb = np.dot(w, x[i]) + b\n",
    "        dj_db += f_wb - y[i]\n",
    "        for j in range(n):\n",
    "            dj_dw[j] += (f_wb - y[i]) * x[i,j] # See Eq. (6) dj_dw[j] >> x[i, j]\n",
    "    \n",
    "    dj_db = dj_db / m\n",
    "    dj_dw = dj_dw / m\n",
    "\n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at initial w,b: -1.6739251501955248e-06\n",
      "dj_dw at initial w,b: \n",
      " [-2.72623577e-03 -6.27197263e-06 -2.21745578e-06 -6.92403391e-05]\n"
     ]
    }
   ],
   "source": [
    "tmp_dj_dw, tmp_dj_db = compute_gradient(x_train, y_train, w_init, b_init)\n",
    "print(f'dj_db at initial w,b: {tmp_dj_db}')\n",
    "print(f'dj_dw at initial w,b: \\n {tmp_dj_dw}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii) Compute Gradient Descent With Multiple Variables (Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w, b, lr, iterations):\n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn w and b. Updates w and b by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))   : Data, m examples with n features\n",
    "      y (ndarray (m,))    : target values\n",
    "      w_in (ndarray (n,)) : initial model parameters  \n",
    "      b_in (scalar)       : initial model parameter\n",
    "      lr (float)          : alpha - Learning rate\n",
    "      iterations (int)     : number of iterations to run gradient descent\n",
    "      \n",
    "    Returns:\n",
    "      w (ndarray (n,)) : Updated values of parameters \n",
    "      b (scalar)       : Updated value of parameter \n",
    "    \"\"\"\n",
    "    steps = iterations // 10\n",
    "    j_history, p_history = [], []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        cost = compute_cost(x,y,w,b)\n",
    "        j_history.append(cost)\n",
    "        p_history.append([w,b])\n",
    "\n",
    "        dj_dw, dj_db = compute_gradient(x,y,w,b)\n",
    "        temp_w = w - lr * dj_dw\n",
    "        temp_b = b - lr * dj_db\n",
    "        w, b = temp_w, temp_b\n",
    "        # print(i, end=\",\")\n",
    "        if (i % steps) == 0:\n",
    "            print(f\"iteration: {i}, cost: {cost}, w:{w}, b:{b}\")\n",
    "    return w, b, j_history #return final w,b and J history for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: [[2104    5    1   45]\n",
      " [1416    3    2   40]\n",
      " [ 852    2    1   35]]; \n",
      "shape: (3, 4), dtype: int32; dimension: 2\n",
      "y_train: [460 232 178]; \n",
      "shape: (3,), dtype: int32; dimension: 1\n",
      "w_init:[0. 0. 0. 0.], \n",
      "b_init:0.0\n",
      "w_init:[0. 0. 0. 0.], \n",
      "b_init:0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train: {x_train}; \\nshape: {x_train.shape}, dtype: {x_train.dtype}; dimension: {x_train.ndim}\")\n",
    "print(f\"y_train: {y_train}; \\nshape: {y_train.shape}, dtype: {y_train.dtype}; dimension: {y_train.ndim}\")\n",
    "print(\"w_init:{}, \\nb_init:{}\".format(w_init, b_init))\n",
    "\n",
    "w_init = np.zeros_like(w_init)\n",
    "b_init = 0.\n",
    "print(\"w_init:{}, \\nb_init:{}\".format(w_init, b_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0, cost: 49518.0, w:[2.41334667e-01 5.58666667e-04 1.83666667e-04 6.03500000e-03], b:0.000145\n",
      "iteration: 100, cost: 696.0010595124644, w:[ 0.20235171  0.00079796 -0.00099658 -0.00219736], b:-0.0001198596187768893\n",
      "iteration: 200, cost: 694.9313476914762, w:[ 0.20253446  0.00112715 -0.00214349 -0.00940619], b:-0.00035965781839536286\n",
      "iteration: 300, cost: 693.8709864577195, w:[ 0.2027164   0.00145611 -0.00328876 -0.01658286], b:-0.0005983240279392168\n",
      "iteration: 400, cost: 692.8198930237817, w:[ 0.20289753  0.00178484 -0.00443238 -0.02372751], b:-0.0008358632706869382\n",
      "iteration: 500, cost: 691.7779853352548, w:[ 0.20307785  0.00211335 -0.00557437 -0.03084027], b:-0.0010722805476294612\n",
      "iteration: 600, cost: 690.7451820642369, w:[ 0.20325736  0.00244162 -0.00671473 -0.0379213 ], b:-0.0013075808375690545\n",
      "iteration: 700, cost: 689.7214026029069, w:[ 0.20343608  0.00276967 -0.00785347 -0.04497072], b:-0.0015417690972177696\n",
      "iteration: 800, cost: 688.706567057147, w:[ 0.20361399  0.00309749 -0.00899059 -0.05198869], b:-0.001774850261295446\n",
      "iteration: 900, cost: 687.7005962402227, w:[ 0.20379112  0.00342509 -0.01012611 -0.05897533], b:-0.0020068292426272975\n",
      "b,w found by gradient descent: -0.00,[ 0.20396569  0.00374919 -0.0112487  -0.0658614 ] \n"
     ]
    }
   ],
   "source": [
    "iterations = 1000\n",
    "# learning_rate = 0.001\n",
    "learning_rate = 5.0e-7\n",
    "\n",
    "# run gradient descent \n",
    "w_final, b_final, J_hist = gradient_descent(x_train, y_train, w_init, b_init, learning_rate, iterations)\n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 426.19, target value: 460\n",
      "prediction: 286.17, target value: 232\n",
      "prediction: 171.47, target value: 178\n"
     ]
    }
   ],
   "source": [
    "m,_ = x_train.shape\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot cost versus iteration  \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True, figsize=(12, 4))\n",
    "ax1.plot(J_hist)\n",
    "ax2.plot(100 + np.arange(len(J_hist[100:])), J_hist[100:])\n",
    "ax1.set_title(\"Cost vs. iteration\");  ax2.set_title(\"Cost vs. iteration (tail)\")\n",
    "ax1.set_ylabel('Cost')             ;  ax2.set_ylabel('Cost') \n",
    "ax1.set_xlabel('iteration step')   ;  ax2.set_xlabel('iteration step') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Go to Home](../)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b1e6b76b6e736d29445d5c5f779c1dafb0f59893c5766b7198bc0a87a8e7acf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
